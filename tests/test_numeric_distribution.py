from functools import reduce
from hypothesis import assume, example, given, settings
import hypothesis.strategies as st
import numpy as np
import operator
from pytest import approx
from scipy import integrate, stats
import sys
import warnings

from ..squigglepy.distributions import (
    ComplexDistribution,
    LognormalDistribution,
    MixtureDistribution,
    NormalDistribution,
    UniformDistribution,
)
from ..squigglepy.numeric_distribution import numeric, NumericDistribution
from ..squigglepy import samplers, utils

# There are a lot of functions testing various combinations of behaviors with
# no obvious way to order them. These functions are ordered basically like this:
#
# 1. helper functions
# 2. tests for constructors for norm and lognorm
# 3. tests for basic operations on norm and lognorm, in the order
#    product > sum > negation > subtraction
# 4. tests for other distributions
# 5. tests for non-operation functions such as cdf/quantile
# 6. special tests, such as profiling tests
#
# Tests with `basic` in the name use hard-coded values to ensure basic
# functionality. Other tests use values generated by the hypothesis library.

TEST_BIN_SIZING_ACCURACY = True

def relative_error(x, y):
    if x == 0 and y == 0:
        return 0
    if x == 0:
        return -1
    if y == 0:
        return np.inf
    return max(x / y, y / x) - 1


def print_accuracy_ratio(x, y, extra_message=None):
    ratio = relative_error(x, y)
    if extra_message is not None:
        extra_message += " "
    else:
        extra_message = ""
    direction_off = "small" if x < y else "large"
    if ratio > 1:
        print(f"{extra_message}Ratio: {direction_off} by a factor of {ratio:.1f}")
    else:
        print(f"{extra_message}Ratio: {direction_off} by {100 * ratio:.3f}%")


def get_mc_accuracy(exact_sd, num_samples, dists, operation):
    # Run multiple trials because NumericDistribution should usually beat MC,
    # but sometimes MC wins by luck. Even though NumericDistribution wins a
    # large percentage of the time, this test suite does a lot of runs, so the
    # chance of MC winning at least once is fairly high.
    mc_abs_error = []
    for i in range(10):
        mcs = [samplers.sample(dist, num_samples) for dist in dists]
        mc = reduce(operation, mcs)
        mc_abs_error.append(abs(np.std(mc) - exact_sd))

    mc_abs_error.sort()

    # Small numbers are good. A smaller index in mc_abs_error has a better
    # accuracy
    return mc_abs_error[-5]


def fix_uniform(a, b):
    """
    Check that a and b are ordered correctly and that they're not tiny enough
    to mess up floating point calculations.
    """
    if a > b:
        a, b = b, a
    assume(a != b)
    assume(((b - a) / (50 * (abs(a) + abs(b)))) ** 2 > sys.float_info.epsilon)
    assume(a == 0 or abs(a) > sys.float_info.epsilon)
    assume(b == 0 or abs(b) > sys.float_info.epsilon)
    return a, b


@given(
    mean1=st.floats(min_value=-1e5, max_value=1e5),
    mean2=st.floats(min_value=-1e5, max_value=1e5),
    sd1=st.floats(min_value=0.1, max_value=100),
    sd2=st.floats(min_value=0.001, max_value=1000),
)
@example(mean1=0, mean2=1025, sd1=1, sd2=1)
def test_sum_exact_summary_stats(mean1, mean2, sd1, sd2):
    """Test that the formulas for exact moments are implemented correctly."""
    dist1 = NormalDistribution(mean=mean1, sd=sd1)
    dist2 = NormalDistribution(mean=mean2, sd=sd2)
    hist1 = numeric(dist1, warn=False)
    hist2 = numeric(dist2, warn=False)
    hist_prod = hist1 + hist2
    assert hist_prod.exact_mean == approx(
        stats.norm.mean(mean1 + mean2, np.sqrt(sd1**2 + sd2**2))
    )
    assert hist_prod.exact_sd == approx(
        stats.norm.std(
            mean1 + mean2,
            np.sqrt(sd1**2 + sd2**2),
        )
    )


@given(
    norm_mean1=st.floats(min_value=-np.log(1e9), max_value=np.log(1e9)),
    norm_mean2=st.floats(min_value=-np.log(1e5), max_value=np.log(1e5)),
    norm_sd1=st.floats(min_value=0.1, max_value=3),
    norm_sd2=st.floats(min_value=0.001, max_value=3),
)
def test_lognorm_product_exact_summary_stats(norm_mean1, norm_mean2, norm_sd1, norm_sd2):
    """Test that the formulas for exact moments are implemented correctly."""
    dist1 = LognormalDistribution(norm_mean=norm_mean1, norm_sd=norm_sd1)
    dist2 = LognormalDistribution(norm_mean=norm_mean2, norm_sd=norm_sd2)
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        hist1 = numeric(dist1, warn=False)
        hist2 = numeric(dist2, warn=False)
    hist_prod = hist1 * hist2
    assert hist_prod.exact_mean == approx(
        stats.lognorm.mean(
            np.sqrt(norm_sd1**2 + norm_sd2**2), scale=np.exp(norm_mean1 + norm_mean2)
        )
    )
    assert hist_prod.exact_sd == approx(
        stats.lognorm.std(
            np.sqrt(norm_sd1**2 + norm_sd2**2), scale=np.exp(norm_mean1 + norm_mean2)
        )
    )


@given(
    mean=st.floats(min_value=-np.log(1e9), max_value=np.log(1e9)),
    sd=st.floats(min_value=0.001, max_value=100),
)
@example(mean=0, sd=1)
def test_norm_basic(mean, sd):
    dist = NormalDistribution(mean=mean, sd=sd)
    hist = numeric(dist, bin_sizing="uniform", warn=True)
    assert hist.histogram_mean() == approx(mean)
    assert hist.histogram_sd() == approx(sd, rel=0.01)


@given(
    norm_mean=st.floats(min_value=-np.log(1e9), max_value=np.log(1e9)),
    norm_sd=st.floats(min_value=0.001, max_value=3),
    bin_sizing=st.sampled_from(["uniform", "log-uniform", "ev", "mass"]),
)
@example(norm_mean=1, norm_sd=2, bin_sizing="mass")
def test_lognorm_mean(norm_mean, norm_sd, bin_sizing):
    dist = LognormalDistribution(norm_mean=norm_mean, norm_sd=norm_sd)
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        hist = numeric(dist, bin_sizing=bin_sizing, warn=False)
    if bin_sizing == "ev":
        tolerance = 1e-6
    elif bin_sizing == "log-uniform":
        tolerance = 1e-2
    else:
        tolerance = 0.01 if dist.norm_sd < 3 else 0.1
    assert hist.histogram_mean() == approx(
        stats.lognorm.mean(dist.norm_sd, scale=np.exp(dist.norm_mean)),
        rel=tolerance,
    )


@given(
    norm_mean=st.floats(min_value=-np.log(1e9), max_value=np.log(1e9)),
    norm_sd=st.floats(min_value=0.01, max_value=3),
)
def test_lognorm_sd(norm_mean, norm_sd):
    test_edges = False
    dist = LognormalDistribution(norm_mean=norm_mean, norm_sd=norm_sd)
    hist = numeric(dist, bin_sizing="log-uniform", warn=False)

    def true_variance(left, right):
        return integrate.quad(
            lambda x: (x - dist.lognorm_mean) ** 2
            * stats.lognorm.pdf(x, dist.norm_sd, scale=np.exp(dist.norm_mean)),
            left,
            right,
        )[0]

    def observed_variance(left, right):
        return np.sum(
            hist.masses[left:right] * (hist.values[left:right] - hist.histogram_mean()) ** 2
        )

    if test_edges:
        # Note: For bin_sizing=ev, adding more bins increases accuracy overall,
        # but decreases accuracy on the far right tail.
        midpoint = hist.values[int(hist.num_bins * 9 / 10)]
        expected_left_variance = true_variance(0, midpoint)
        expected_right_variance = true_variance(midpoint, np.inf)
        midpoint_index = int(len(hist) * hist.contribution_to_ev(midpoint))
        observed_left_variance = observed_variance(0, midpoint_index)
        observed_right_variance = observed_variance(midpoint_index, len(hist))
        print("")
        print_accuracy_ratio(observed_left_variance, expected_left_variance, "Left   ")
        print_accuracy_ratio(observed_right_variance, expected_right_variance, "Right  ")
        print_accuracy_ratio(hist.histogram_sd(), dist.lognorm_sd, "Overall")

    assert hist.histogram_sd() == approx(dist.lognorm_sd, rel=0.01 + 0.1 * norm_sd)


def test_norm_sd_bin_sizing_accuracy():
    if not TEST_BIN_SIZING_ACCURACY:
        return None
    # Accuracy order is ev > uniform > mass
    dist = NormalDistribution(mean=0, sd=1)
    ev_hist = numeric(dist, bin_sizing="ev", warn=False)
    mass_hist = numeric(dist, bin_sizing="mass", warn=False)
    uniform_hist = numeric(dist, bin_sizing="uniform", warn=False)

    sd_errors = [
        relative_error(ev_hist.histogram_sd(), dist.sd),
        relative_error(uniform_hist.histogram_sd(), dist.sd),
        relative_error(mass_hist.histogram_sd(), dist.sd),
    ]
    assert all(np.diff(sd_errors) >= 0)


def test_norm_product_bin_sizing_accuracy():
    if not TEST_BIN_SIZING_ACCURACY:
        return None
    dist = NormalDistribution(mean=2, sd=1)
    uniform_hist = numeric(dist, bin_sizing="uniform", warn=False)
    uniform_hist = uniform_hist * uniform_hist
    ev_hist = numeric(dist, bin_sizing="ev", warn=False)
    ev_hist = ev_hist * ev_hist
    mass_hist = numeric(dist, bin_sizing="mass", warn=False)
    mass_hist = mass_hist * mass_hist

    # uniform and log-uniform should have small errors and the others should be
    # pretty much perfect
    mean_errors = [
        relative_error(ev_hist.histogram_mean(), ev_hist.exact_mean),
        relative_error(mass_hist.histogram_mean(), ev_hist.exact_mean),
        relative_error(uniform_hist.histogram_mean(), ev_hist.exact_mean),
    ]
    assert all(np.diff(mean_errors) >= 0)

    sd_errors = [
        relative_error(uniform_hist.histogram_sd(), ev_hist.exact_sd),
        relative_error(mass_hist.histogram_sd(), ev_hist.exact_sd),
        relative_error(ev_hist.histogram_sd(), ev_hist.exact_sd),
    ]
    assert all(np.diff(sd_errors) >= 0)


def test_lognorm_product_bin_sizing_accuracy():
    if not TEST_BIN_SIZING_ACCURACY:
        return None
    dist = LognormalDistribution(norm_mean=np.log(1e6), norm_sd=1)
    uniform_hist = numeric(dist, bin_sizing="uniform", warn=False)
    uniform_hist = uniform_hist * uniform_hist
    log_uniform_hist = numeric(
        dist, bin_sizing="log-uniform", warn=False
    )
    log_uniform_hist = log_uniform_hist * log_uniform_hist
    ev_hist = numeric(dist, bin_sizing="ev", warn=False)
    ev_hist = ev_hist * ev_hist
    mass_hist = numeric(dist, bin_sizing="mass", warn=False)
    mass_hist = mass_hist * mass_hist
    fat_hybrid_hist = numeric(dist, bin_sizing="fat-hybrid", warn=False)
    fat_hybrid_hist = fat_hybrid_hist * fat_hybrid_hist
    dist_prod = LognormalDistribution(norm_mean=2 * dist.norm_mean, norm_sd=np.sqrt(2) * dist.norm_sd)

    mean_errors = [
        relative_error(fat_hybrid_hist.histogram_mean(), dist_prod.lognorm_mean),
        relative_error(mass_hist.histogram_mean(), dist_prod.lognorm_mean),
        relative_error(ev_hist.histogram_mean(), dist_prod.lognorm_mean),
        relative_error(uniform_hist.histogram_mean(), dist_prod.lognorm_mean),
        relative_error(log_uniform_hist.histogram_mean(), dist_prod.lognorm_mean),
    ]
    assert all(np.diff(mean_errors) >= 0)

    sd_errors = [
        relative_error(fat_hybrid_hist.histogram_sd(), dist_prod.lognorm_sd),
        relative_error(log_uniform_hist.histogram_sd(), dist_prod.lognorm_sd),
        relative_error(ev_hist.histogram_sd(), dist_prod.lognorm_sd),
        relative_error(mass_hist.histogram_sd(), dist_prod.lognorm_sd),
        relative_error(uniform_hist.histogram_sd(), dist_prod.lognorm_sd),
    ]
    assert all(np.diff(sd_errors) >= 0)


def test_lognorm_clip_center_bin_sizing_accuracy():
    if not TEST_BIN_SIZING_ACCURACY:
        return None
    dist1 = LognormalDistribution(norm_mean=-1, norm_sd=0.5, lclip=0, rclip=1)
    dist2 = LognormalDistribution(norm_mean=0, norm_sd=1, lclip=0, rclip=2*np.e)
    true_mean1 = stats.lognorm.expect(lambda x: x, args=(dist1.norm_sd,), scale=np.exp(dist1.norm_mean), lb=dist1.lclip, ub=dist1.rclip, conditional=True)
    true_sd1 = np.sqrt(stats.lognorm.expect(lambda x: (x - true_mean1) ** 2, args=(dist1.norm_sd,), scale=np.exp(dist1.norm_mean), lb=dist1.lclip, ub=dist1.rclip, conditional=True))
    true_mean2 = stats.lognorm.expect(lambda x: x, args=(dist2.norm_sd,), scale=np.exp(dist2.norm_mean), lb=dist2.lclip, ub=dist2.rclip, conditional=True)
    true_sd2 = np.sqrt(stats.lognorm.expect(lambda x: (x - true_mean2) ** 2, args=(dist2.norm_sd,), scale=np.exp(dist2.norm_mean), lb=dist2.lclip, ub=dist2.rclip, conditional=True))
    true_mean = true_mean1 * true_mean2
    true_sd = np.sqrt(true_sd1**2 * true_mean2**2 + true_mean1**2 * true_sd2**2 + true_sd1**2 * true_sd2**2)

    uniform_hist = numeric(dist1, bin_sizing="uniform", warn=False) * numeric(dist2, bin_sizing="uniform", warn=False)
    log_uniform_hist = numeric(
        dist1, bin_sizing="log-uniform", warn=False
    ) * numeric(dist2, bin_sizing="log-uniform", warn=False)
    ev_hist = numeric(dist1, bin_sizing="ev", warn=False) * numeric(dist2, bin_sizing="ev", warn=False)
    mass_hist = numeric(dist1, bin_sizing="mass", warn=False) * numeric(dist2, bin_sizing="mass", warn=False)
    fat_hybrid_hist = numeric(dist1, bin_sizing="fat-hybrid", warn=False) * numeric(dist2, bin_sizing="fat-hybrid", warn=False)

    mean_errors = [
        relative_error(ev_hist.histogram_mean(), true_mean),
        relative_error(uniform_hist.histogram_mean(), true_mean),
        relative_error(mass_hist.histogram_mean(), true_mean),
        relative_error(fat_hybrid_hist.histogram_mean(), true_mean),
        relative_error(log_uniform_hist.histogram_mean(), true_mean),
    ]
    assert all(np.diff(mean_errors) >= 0)

    # Uniform does poorly in general with fat-tailed dists, but it does well
    # with a center clip because most of the mass is in the center
    sd_errors = [
        relative_error(mass_hist.histogram_mean(), true_mean),
        relative_error(uniform_hist.histogram_sd(), true_sd),
        relative_error(ev_hist.histogram_sd(), true_sd),
        relative_error(fat_hybrid_hist.histogram_sd(), true_sd),
        relative_error(log_uniform_hist.histogram_sd(), true_sd),
    ]
    assert all(np.diff(sd_errors) >= 0)


def test_lognorm_clip_tail_bin_sizing_accuracy():
    if not TEST_BIN_SIZING_ACCURACY:
        return None
    # cut off 99% of mass and 95% of mass, respectively
    dist1 = LognormalDistribution(norm_mean=0, norm_sd=1, lclip=10)
    dist2 = LognormalDistribution(norm_mean=0, norm_sd=2, rclip=27)
    true_mean1 = stats.lognorm.expect(lambda x: x, args=(dist1.norm_sd,), scale=np.exp(dist1.norm_mean), lb=dist1.lclip, ub=dist1.rclip, conditional=True)
    true_sd1 = np.sqrt(stats.lognorm.expect(lambda x: (x - true_mean1) ** 2, args=(dist1.norm_sd,), scale=np.exp(dist1.norm_mean), lb=dist1.lclip, conditional=True))
    true_mean2 = stats.lognorm.expect(lambda x: x, args=(dist2.norm_sd,), scale=np.exp(dist2.norm_mean), lb=dist2.lclip, ub=dist2.rclip, conditional=True)
    true_sd2 = np.sqrt(stats.lognorm.expect(lambda x: (x - true_mean2) ** 2, args=(dist2.norm_sd,), scale=np.exp(dist2.norm_mean), lb=dist2.lclip, conditional=True))
    true_mean = true_mean1 * true_mean2
    true_sd = np.sqrt(true_sd1**2 * true_mean2**2 + true_mean1**2 * true_sd2**2 + true_sd1**2 * true_sd2**2)

    uniform_hist = numeric(dist1, bin_sizing="uniform", warn=False) * numeric(dist2, bin_sizing="uniform", warn=False)
    log_uniform_hist = numeric(
        dist1, bin_sizing="log-uniform", warn=False
    ) * numeric(dist2, bin_sizing="log-uniform", warn=False)
    ev_hist = numeric(dist1, bin_sizing="ev", warn=False) * numeric(dist2, bin_sizing="ev", warn=False)
    mass_hist = numeric(dist1, bin_sizing="mass", warn=False) * numeric(dist2, bin_sizing="mass", warn=False)
    fat_hybrid_hist = numeric(dist1, bin_sizing="fat-hybrid", warn=False) * numeric(dist2, bin_sizing="fat-hybrid", warn=False)

    mean_errors = [
        relative_error(mass_hist.histogram_mean(), true_mean),
        relative_error(uniform_hist.histogram_mean(), true_mean),
        relative_error(fat_hybrid_hist.histogram_mean(), true_mean),
        relative_error(ev_hist.histogram_mean(), true_mean),
        relative_error(log_uniform_hist.histogram_mean(), true_mean),
    ]
    assert all(np.diff(mean_errors) >= 0)

    sd_errors = [
        relative_error(fat_hybrid_hist.histogram_sd(), true_sd),
        relative_error(log_uniform_hist.histogram_sd(), true_sd),
        relative_error(ev_hist.histogram_sd(), true_sd),
        relative_error(mass_hist.histogram_sd(), true_sd),
        relative_error(uniform_hist.histogram_sd(), true_sd),
    ]
    assert all(np.diff(sd_errors) >= 0)


@given(
    mean=st.floats(min_value=-10, max_value=10),
    sd=st.floats(min_value=0.01, max_value=10),
    clip_zscore=st.floats(min_value=-4, max_value=4),
)
def test_norm_one_sided_clip(mean, sd, clip_zscore):
    tolerance = 1e-3 if abs(clip_zscore) > 3 else 1e-5
    clip = mean + clip_zscore * sd
    dist = NormalDistribution(mean=mean, sd=sd, lclip=clip)
    hist = numeric(dist, warn=False)
    assert hist.histogram_mean() == approx(
        stats.truncnorm.mean(clip_zscore, np.inf, loc=mean, scale=sd), rel=tolerance, abs=tolerance
    )

    # The exact mean can still be a bit off because uniform bin_sizing doesn't
    # cover the full domain
    assert hist.exact_mean == approx(
        stats.truncnorm.mean(clip_zscore, np.inf, loc=mean, scale=sd), rel=1e-6, abs=1e-10
    )

    dist = NormalDistribution(mean=mean, sd=sd, rclip=clip)
    hist = numeric(dist, warn=False)
    assert hist.histogram_mean() == approx(
        stats.truncnorm.mean(-np.inf, clip_zscore, loc=mean, scale=sd),
        rel=tolerance,
        abs=tolerance,
    )
    assert hist.exact_mean == approx(
        stats.truncnorm.mean(-np.inf, clip_zscore, loc=mean, scale=sd), rel=1e-5, abs=1e-6
    )


@given(
    mean=st.floats(min_value=-1, max_value=1),
    sd=st.floats(min_value=0.01, max_value=10),
    lclip_zscore=st.floats(min_value=-4, max_value=4),
    rclip_zscore=st.floats(min_value=-4, max_value=4),
)
def test_norm_clip(mean, sd, lclip_zscore, rclip_zscore):
    tolerance = 1e-3 if max(abs(lclip_zscore), abs(rclip_zscore)) > 3 else 1e-5
    if lclip_zscore > rclip_zscore:
        lclip_zscore, rclip_zscore = rclip_zscore, lclip_zscore
    assume(abs(rclip_zscore - lclip_zscore) > 0.01)
    lclip = mean + lclip_zscore * sd
    rclip = mean + rclip_zscore * sd
    dist = NormalDistribution(mean=mean, sd=sd, lclip=lclip, rclip=rclip)
    hist = numeric(dist, warn=False)

    assert hist.histogram_mean() == approx(
        stats.truncnorm.mean(lclip_zscore, rclip_zscore, loc=mean, scale=sd), rel=tolerance
    )
    assert hist.histogram_mean() == approx(hist.exact_mean, rel=tolerance)
    assert hist.exact_mean == approx(
        stats.truncnorm.mean(lclip_zscore, rclip_zscore, loc=mean, scale=sd), rel=1e-6, abs=1e-10
    )
    assert hist.exact_sd == approx(
        stats.truncnorm.std(lclip_zscore, rclip_zscore, loc=mean, scale=sd), rel=1e-6, abs=1e-10
    )


@given(
    a=st.floats(-100, -1),
    b=st.floats(1, 100),
    lclip=st.floats(-100, -1),
    rclip=st.floats(1, 100),
)
def test_uniform_clip(a, b, lclip, rclip):
    dist = UniformDistribution(a, b)
    dist.lclip = lclip
    dist.rclip = rclip
    narrow_dist = UniformDistribution(max(a, lclip), min(b, rclip))
    hist = numeric(dist)
    narrow_hist = numeric(narrow_dist)

    assert hist.histogram_mean() == approx(narrow_hist.exact_mean)
    assert hist.histogram_mean() == approx(narrow_hist.histogram_mean())
    assert hist.values[0] == approx(narrow_hist.values[0])
    assert hist.values[-1] == approx(narrow_hist.values[-1])


@given(
    norm_mean=st.floats(min_value=0.1, max_value=10),
    norm_sd=st.floats(min_value=0.5, max_value=3),
    clip_zscore=st.floats(min_value=-2, max_value=2),
)
def test_lognorm_clip_and_sum(norm_mean, norm_sd, clip_zscore):
    clip = np.exp(norm_mean + norm_sd * clip_zscore)
    left_dist = LognormalDistribution(norm_mean=norm_mean, norm_sd=norm_sd, rclip=clip)
    right_dist = LognormalDistribution(norm_mean=norm_mean, norm_sd=norm_sd, lclip=clip)
    left_hist = numeric(left_dist, warn=False)
    right_hist = numeric(right_dist, warn=False)
    left_mass = stats.lognorm.cdf(clip, norm_sd, scale=np.exp(norm_mean))
    right_mass = 1 - left_mass
    true_mean = stats.lognorm.mean(norm_sd, scale=np.exp(norm_mean))
    sum_exact_mean = left_mass * left_hist.exact_mean + right_mass * right_hist.exact_mean
    sum_hist_mean = (
        left_mass * left_hist.histogram_mean() + right_mass * right_hist.histogram_mean()
    )

    # TODO: the error margin is surprisingly large
    assert sum_exact_mean == approx(true_mean, rel=1e-3, abs=1e-6)
    assert sum_hist_mean == approx(true_mean, rel=1e-3, abs=1e-6)


@given(
    mean1=st.floats(min_value=-1000, max_value=0.01),
    mean2=st.floats(min_value=0.01, max_value=1000),
    mean3=st.floats(min_value=0.01, max_value=1000),
    sd1=st.floats(min_value=0.1, max_value=10),
    sd2=st.floats(min_value=0.1, max_value=10),
    sd3=st.floats(min_value=0.1, max_value=10),
    bin_sizing=st.sampled_from(["ev", "mass", "uniform"]),
)
@example(mean1=0, mean2=1000, mean3=617, sd1=1.5, sd2=1.5, sd3=1, bin_sizing="ev")
def test_norm_product(mean1, mean2, mean3, sd1, sd2, sd3, bin_sizing):
    dist1 = NormalDistribution(mean=mean1, sd=sd1)
    dist2 = NormalDistribution(mean=mean2, sd=sd2)
    dist3 = NormalDistribution(mean=mean3, sd=sd3)
    mean_tolerance = 1e-5
    sd_tolerance = 0.2 if bin_sizing == "uniform" else 1
    hist1 = numeric(
        dist1, num_bins=25, bin_sizing=bin_sizing, warn=False
    )
    hist2 = numeric(
        dist2, num_bins=25, bin_sizing=bin_sizing, warn=False
    )
    hist3 = numeric(
        dist3, num_bins=25, bin_sizing=bin_sizing, warn=False
    )
    hist_prod = hist1 * hist2
    assert hist_prod.histogram_mean() == approx(
        dist1.mean * dist2.mean, rel=mean_tolerance, abs=1e-8
    )
    assert hist_prod.histogram_sd() == approx(
        np.sqrt(
            (dist1.sd**2 + dist1.mean**2) * (dist2.sd**2 + dist2.mean**2)
            - dist1.mean**2 * dist2.mean**2
        ),
        rel=sd_tolerance,
    )
    hist3_prod = hist_prod * hist3
    assert hist3_prod.histogram_mean() == approx(
        dist1.mean * dist2.mean * dist3.mean, rel=mean_tolerance, abs=1e-9
    )


@given(
    mean=st.floats(min_value=-10, max_value=10),
    sd=st.floats(min_value=0.001, max_value=100),
    num_bins=st.sampled_from([25, 100]),
    bin_sizing=st.sampled_from(["ev", "mass", "uniform"]),
)
@settings(max_examples=100)
def test_norm_mean_error_propagation(mean, sd, num_bins, bin_sizing):
    """ "Test how quickly the error in the mean grows as distributions are
    multiplied."""
    dist = NormalDistribution(mean=mean, sd=sd)
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        hist = numeric(
            dist, num_bins=num_bins, bin_sizing=bin_sizing
        )
        hist_base = numeric(
            dist, num_bins=num_bins, bin_sizing=bin_sizing
        )
    tolerance = 1e-10 if bin_sizing == "ev" else 1e-5

    for i in range(1, 17):
        true_mean = mean**i
        true_sd = np.sqrt((dist.sd**2 + dist.mean**2) ** i - dist.mean ** (2 * i))
        if true_sd > 1e15:
            break
        assert hist.histogram_mean() == approx(
            true_mean, abs=tolerance ** (1 / i), rel=tolerance ** (1 / i)
        ), f"On iteration {i}"
        hist = hist * hist_base


@given(
    mean1=st.floats(min_value=-100, max_value=100),
    mean2=st.floats(min_value=-np.log(1e5), max_value=np.log(1e5)),
    mean3=st.floats(min_value=-100, max_value=100),
    sd1=st.floats(min_value=0.001, max_value=100),
    sd2=st.floats(min_value=0.001, max_value=3),
    sd3=st.floats(min_value=0.001, max_value=100),
    num_bins1=st.sampled_from([25, 100]),
    num_bins2=st.sampled_from([25, 100]),
)
def test_norm_lognorm_product_sum(mean1, mean2, mean3, sd1, sd2, sd3, num_bins1, num_bins2):
    dist1 = NormalDistribution(mean=mean1, sd=sd1)
    dist2 = LognormalDistribution(norm_mean=mean2, norm_sd=sd2)
    dist3 = NormalDistribution(mean=mean3, sd=sd3)
    hist1 = numeric(dist1, num_bins=num_bins1, warn=False)
    hist2 = numeric(
        dist2, num_bins=num_bins2, bin_sizing="ev", warn=False
    )
    hist3 = numeric(dist3, num_bins=num_bins1, warn=False)
    hist_prod = hist1 * hist2
    assert all(np.diff(hist_prod.values) >= 0)
    assert hist_prod.histogram_mean() == approx(hist_prod.exact_mean, abs=1e-5, rel=1e-5)

    # SD is pretty inaccurate
    sd_tolerance = 1 if num_bins1 == 100 and num_bins2 == 100 else 2
    assert hist_prod.histogram_sd() == approx(hist_prod.exact_sd, rel=sd_tolerance)

    hist_sum = hist_prod + hist3
    assert hist_sum.histogram_mean() == approx(hist_sum.exact_mean, abs=1e-5, rel=1e-5)


@given(
    norm_mean=st.floats(min_value=np.log(1e-9), max_value=np.log(1e9)),
    norm_sd=st.floats(min_value=0.001, max_value=3),
    num_bins=st.sampled_from([25, 100]),
    bin_sizing=st.sampled_from(["ev", "log-uniform"]),
)
@example(norm_mean=0.0, norm_sd=1.0, num_bins=25, bin_sizing="ev").via("discovered failure")
def test_lognorm_mean_error_propagation(norm_mean, norm_sd, num_bins, bin_sizing):
    assume(not (num_bins == 10 and bin_sizing == "log-uniform"))
    dist = LognormalDistribution(norm_mean=norm_mean, norm_sd=norm_sd)
    hist = numeric(
        dist, num_bins=num_bins, bin_sizing=bin_sizing, warn=False
    )
    hist_base = numeric(
        dist, num_bins=num_bins, bin_sizing=bin_sizing, warn=False
    )
    inv_tolerance = 1 - 1e-12 if bin_sizing == "ev" else 0.98

    for i in range(1, 13):
        true_mean = stats.lognorm.mean(np.sqrt(i) * norm_sd, scale=np.exp(i * norm_mean))
        if bin_sizing == "ev":
            # log-uniform can have out-of-order values due to the masses at the
            # end being very small
            assert all(np.diff(hist.values) >= 0), f"On iteration {i}: {hist.values}"
        assert hist.histogram_mean() == approx(
            true_mean, rel=1 - inv_tolerance**i
        ), f"On iteration {i}"
        hist = hist * hist_base


@given(bin_sizing=st.sampled_from(["ev", "log-uniform"]))
def test_lognorm_sd_error_propagation(bin_sizing):
    verbose = False
    dist = LognormalDistribution(norm_mean=0, norm_sd=1)
    num_bins = 100
    hist = numeric(
        dist, num_bins=num_bins, bin_sizing=bin_sizing, warn=False
    )
    abs_error = []
    rel_error = []

    if verbose:
        print("")
    for i in [1, 2, 4, 8, 16, 32]:
        true_mean = stats.lognorm.mean(np.sqrt(i))
        true_sd = hist.exact_sd
        abs_error.append(abs(hist.histogram_sd() - true_sd))
        rel_error.append(relative_error(hist.histogram_sd(), true_sd))
        if verbose:
            print(f"n = {i:2d}: {rel_error[-1]*100:4.1f}% from SD {hist.histogram_sd():.3f}")
        hist = hist * hist

    expected_error_pcts = (
        [0.9, 2.8, 9.9, 40.7, 211, 2678]
        if bin_sizing == "ev"
        else [12, 26.3, 99.8, 733, 32000, 1e9]
    )

    for i in range(len(expected_error_pcts)):
        assert rel_error[i] < expected_error_pcts[i] / 100


@given(
    norm_mean1=st.floats(min_value=-np.log(1e9), max_value=np.log(1e9)),
    norm_mean2=st.floats(min_value=-np.log(1e9), max_value=np.log(1e9)),
    norm_sd1=st.floats(min_value=0.1, max_value=3),
    norm_sd2=st.floats(min_value=0.1, max_value=3),
    bin_sizing=st.sampled_from(["ev", "log-uniform", "fat-hybrid"]),
)
@example(norm_mean1=0, norm_mean2=0, norm_sd1=3, norm_sd2=3, bin_sizing="log-uniform")
def test_lognorm_product(norm_mean1, norm_sd1, norm_mean2, norm_sd2, bin_sizing):
    dists = [
        LognormalDistribution(norm_mean=norm_mean2, norm_sd=norm_sd2),
        LognormalDistribution(norm_mean=norm_mean1, norm_sd=norm_sd1),
    ]
    dist_prod = LognormalDistribution(
        norm_mean=norm_mean1 + norm_mean2, norm_sd=np.sqrt(norm_sd1**2 + norm_sd2**2)
    )
    hists = [numeric(dist, bin_sizing=bin_sizing, warn=False) for dist in dists]
    hist_prod = reduce(lambda acc, hist: acc * hist, hists)

    # Lognorm width grows with e**norm_sd**2, so error tolerance grows the same way
    sd_tolerance = 1.05 ** (1 + (norm_sd1 + norm_sd2) ** 2) - 1
    mean_tolerance = 1e-3 if bin_sizing == "log-uniform" else 1e-6
    assert hist_prod.histogram_mean() == approx(dist_prod.lognorm_mean, rel=mean_tolerance)
    assert hist_prod.histogram_sd() == approx(dist_prod.lognorm_sd, rel=sd_tolerance)


@given(
    norm_mean1=st.floats(-1e5, 1e5),
    norm_mean2=st.floats(min_value=-1e5, max_value=1e5),
    norm_sd1=st.floats(min_value=0.001, max_value=1e5),
    norm_sd2=st.floats(min_value=0.001, max_value=1e5),
    num_bins1=st.sampled_from([25, 100]),
    num_bins2=st.sampled_from([25, 100]),
    bin_sizing=st.sampled_from(["ev", "uniform"]),
)
@example(
    norm_mean1=99998,
    norm_mean2=-99998,
    norm_sd1=1,
    norm_sd2=1,
    num_bins1=100,
    num_bins2=100,
    bin_sizing="uniform",
)
def test_norm_sum(norm_mean1, norm_mean2, norm_sd1, norm_sd2, num_bins1, num_bins2, bin_sizing):
    dist1 = NormalDistribution(mean=norm_mean1, sd=norm_sd1)
    dist2 = NormalDistribution(mean=norm_mean2, sd=norm_sd2)
    hist1 = numeric(dist1, num_bins=num_bins1, bin_sizing=bin_sizing)
    hist2 = numeric(dist2, num_bins=num_bins2, bin_sizing=bin_sizing)
    hist_sum = hist1 + hist2

    # The further apart the means are, the less accurate the SD estimate is
    distance_apart = abs(norm_mean1 - norm_mean2) / hist_sum.exact_sd
    sd_tolerance = 2 + 0.5 * distance_apart
    mean_tolerance = 1e-10 + 1e-10 * distance_apart

    assert all(np.diff(hist_sum.values) >= 0)
    assert hist_sum.histogram_mean() == approx(hist_sum.exact_mean, abs=mean_tolerance, rel=1e-5)
    assert hist_sum.histogram_sd() == approx(hist_sum.exact_sd, rel=sd_tolerance)


@given(
    norm_mean1=st.floats(min_value=-np.log(1e6), max_value=np.log(1e6)),
    norm_mean2=st.floats(min_value=-np.log(1e6), max_value=np.log(1e6)),
    norm_sd1=st.floats(min_value=0.1, max_value=3),
    norm_sd2=st.floats(min_value=0.01, max_value=3),
    bin_sizing=st.sampled_from(["ev", "log-uniform"]),
)
def test_lognorm_sum(norm_mean1, norm_mean2, norm_sd1, norm_sd2, bin_sizing):
    dist1 = LognormalDistribution(norm_mean=norm_mean1, norm_sd=norm_sd1)
    dist2 = LognormalDistribution(norm_mean=norm_mean2, norm_sd=norm_sd2)
    hist1 = numeric(dist1, bin_sizing=bin_sizing, warn=False)
    hist2 = numeric(dist2, bin_sizing=bin_sizing, warn=False)
    hist_sum = hist1 + hist2
    assert all(np.diff(hist_sum.values) >= 0), hist_sum.values
    mean_tolerance = 1e-3 if bin_sizing == "log-uniform" else 1e-6
    assert hist_sum.histogram_mean() == approx(hist_sum.exact_mean, rel=mean_tolerance)

    # SD is very inaccurate because adding lognormals produces some large but
    # very low-probability values on the right tail and the only approach is to
    # either downweight them or make the histogram much wider.
    assert hist_sum.histogram_sd() > min(hist1.histogram_sd(), hist2.histogram_sd())
    assert hist_sum.histogram_sd() == approx(hist_sum.exact_sd, rel=2)


@given(
    mean1=st.floats(min_value=-100, max_value=100),
    mean2=st.floats(min_value=-np.log(1e5), max_value=np.log(1e5)),
    sd1=st.floats(min_value=0.001, max_value=100),
    sd2=st.floats(min_value=0.001, max_value=3),
    lognorm_bin_sizing=st.sampled_from(["ev", "log-uniform"]),
)
def test_norm_lognorm_sum(mean1, mean2, sd1, sd2, lognorm_bin_sizing):
    dist1 = NormalDistribution(mean=mean1, sd=sd1)
    dist2 = LognormalDistribution(norm_mean=mean2, norm_sd=sd2)
    hist1 = numeric(dist1, warn=False)
    hist2 = numeric(dist2, bin_sizing=lognorm_bin_sizing, warn=False)
    hist_sum = hist1 + hist2
    mean_tolerance = 0.005 if lognorm_bin_sizing == "log-uniform" else 1e-6
    sd_tolerance = 0.5
    assert all(np.diff(hist_sum.values) >= 0), hist_sum.values
    assert hist_sum.histogram_mean() == approx(hist_sum.exact_mean, abs=mean_tolerance, rel=mean_tolerance)
    assert hist_sum.histogram_sd() == approx(hist_sum.exact_sd, rel=sd_tolerance)


def test_norm_product_sd_accuracy_vs_monte_carlo():
    """Test that PMH SD is more accurate than Monte Carlo SD both for initial
    distributions and when multiplying up to 8 distributions together.

    Note: With more multiplications, MC has a good chance of being more
    accurate, and is significantly more accurate at 16 multiplications.
    """
    # Time complexity for binary operations is roughly O(n^2) for PMH and O(n)
    # for MC, so let MC have num_bins^2 samples.
    num_bins = 100
    num_samples = 100**2
    dists = [NormalDistribution(mean=i, sd=0.5 + i / 4) for i in range(9)]
    hists = [
        numeric(dist, num_bins=num_bins, warn=False)
        for dist in dists
    ]
    hist = reduce(lambda acc, hist: acc * hist, hists)
    dist_abs_error = abs(hist.histogram_sd() - hist.exact_sd)

    mc_abs_error = get_mc_accuracy(hist.exact_sd, num_samples, dists, lambda acc, mc: acc * mc)
    assert dist_abs_error < mc_abs_error


def test_lognorm_product_sd_accuracy_vs_monte_carlo():
    """Test that PMH SD is more accurate than Monte Carlo SD both for initial
    distributions and when multiplying up to 16 distributions together."""
    num_bins = 100
    num_samples = 100**2
    dists = [LognormalDistribution(norm_mean=i, norm_sd=0.5 + i / 4) for i in range(9)]
    hists = [
        numeric(dist, num_bins=num_bins, warn=False)
        for dist in dists
    ]
    hist = reduce(lambda acc, hist: acc * hist, hists)
    dist_abs_error = abs(hist.histogram_sd() - hist.exact_sd)

    mc_abs_error = get_mc_accuracy(hist.exact_sd, num_samples, dists, lambda acc, mc: acc * mc)
    assert dist_abs_error < mc_abs_error


def test_norm_sum_sd_accuracy_vs_monte_carlo():
    """Test that PMH SD is more accurate than Monte Carlo SD both for initial
    distributions and when multiplying up to 8 distributions together.

    Note: With more multiplications, MC has a good chance of being more
    accurate, and is significantly more accurate at 16 multiplications.
    """
    num_bins = 1000
    num_samples = num_bins**2
    dists = [NormalDistribution(mean=i, sd=0.5 + i / 4) for i in range(9)]
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        hists = [
            numeric(dist, num_bins=num_bins, bin_sizing="uniform")
            for dist in dists
        ]
    hist = reduce(lambda acc, hist: acc + hist, hists)
    dist_abs_error = abs(hist.histogram_sd() - hist.exact_sd)

    mc_abs_error = get_mc_accuracy(hist.exact_sd, num_samples, dists, lambda acc, mc: acc + mc)
    assert dist_abs_error < mc_abs_error


def test_lognorm_sum_sd_accuracy_vs_monte_carlo():
    """Test that PMH SD is more accurate than Monte Carlo SD both for initial
    distributions and when multiplying up to 16 distributions together."""
    num_bins = 100
    num_samples = 100**2
    dists = [LognormalDistribution(norm_mean=i, norm_sd=0.5 + i / 4) for i in range(17)]
    hists = [
        numeric(dist, num_bins=num_bins, warn=False)
        for dist in dists
    ]
    hist = reduce(lambda acc, hist: acc + hist, hists)
    dist_abs_error = abs(hist.histogram_sd() - hist.exact_sd)

    mc_abs_error = get_mc_accuracy(hist.exact_sd, num_samples, dists, lambda acc, mc: acc + mc)
    assert dist_abs_error < mc_abs_error


@given(
    norm_mean=st.floats(min_value=-1e6, max_value=1e6),
    norm_sd=st.floats(min_value=0.001, max_value=3),
    num_bins=st.sampled_from([25, 100]),
    bin_sizing=st.sampled_from(["ev", "uniform"]),
)
def test_norm_negate(norm_mean, norm_sd, num_bins, bin_sizing):
    dist = NormalDistribution(mean=0, sd=1)
    hist = numeric(dist, warn=False)
    neg_hist = -hist
    assert neg_hist.histogram_mean() == approx(-hist.histogram_mean())
    assert neg_hist.histogram_sd() == approx(hist.histogram_sd())


@given(
    norm_mean=st.floats(min_value=-np.log(1e9), max_value=np.log(1e9)),
    norm_sd=st.floats(min_value=0.001, max_value=3),
    num_bins=st.sampled_from([25, 100]),
    bin_sizing=st.sampled_from(["ev", "uniform"]),
)
def test_lognorm_negate(norm_mean, norm_sd, num_bins, bin_sizing):
    dist = LognormalDistribution(norm_mean=0, norm_sd=1)
    hist = numeric(dist, warn=False)
    neg_hist = -hist
    assert neg_hist.histogram_mean() == approx(-hist.histogram_mean())
    assert neg_hist.histogram_sd() == approx(hist.histogram_sd())


@given(
    type_and_size=st.sampled_from(["norm-ev", "norm-uniform", "lognorm-ev"]),
    mean1=st.floats(min_value=-1e6, max_value=1e6),
    mean2=st.floats(min_value=-100, max_value=100),
    sd1=st.floats(min_value=0.001, max_value=1000),
    sd2=st.floats(min_value=0.1, max_value=5),
    num_bins=st.sampled_from([30, 100]),
)
def test_sub(type_and_size, mean1, mean2, sd1, sd2, num_bins):
    dist1 = NormalDistribution(mean=mean1, sd=sd1)
    dist2_type, bin_sizing = type_and_size.split("-")

    if dist2_type == "norm":
        dist2 = NormalDistribution(mean=mean2, sd=sd2)
        neg_dist = NormalDistribution(mean=-mean2, sd=sd2)
    elif dist2_type == "lognorm":
        dist2 = LognormalDistribution(norm_mean=mean2, norm_sd=sd2)
        # We can't negate a lognormal distribution by changing the params
        neg_dist = None

    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        hist1 = numeric(
            dist1, num_bins=num_bins, bin_sizing=bin_sizing
        )
        hist2 = numeric(
            dist2, num_bins=num_bins, bin_sizing=bin_sizing
        )
    hist_diff = hist1 - hist2
    backward_diff = hist2 - hist1
    assert not any(np.isnan(hist_diff.values))
    assert all(np.diff(hist_diff.values) >= 0)
    assert hist_diff.histogram_mean() == approx(-backward_diff.histogram_mean(), rel=0.01)
    assert hist_diff.histogram_sd() == approx(backward_diff.histogram_sd(), rel=0.05)

    if neg_dist:
        neg_hist = numeric(
            neg_dist, num_bins=num_bins, bin_sizing=bin_sizing
        )
        hist_sum = hist1 + neg_hist
        assert hist_diff.histogram_mean() == approx(hist_sum.histogram_mean(), rel=0.01)
        assert hist_diff.histogram_sd() == approx(hist_sum.histogram_sd(), rel=0.05)


def test_lognorm_sub():
    dist = LognormalDistribution(norm_mean=0, norm_sd=1)
    hist = numeric(dist, warn=False)
    hist_diff = 0.97 * hist - 0.03 * hist
    assert not any(np.isnan(hist_diff.values))
    assert all(np.diff(hist_diff.values) >= 0)
    assert hist_diff.histogram_mean() == approx(0.94 * dist.lognorm_mean, rel=0.001)
    assert hist_diff.histogram_sd() == approx(hist_diff.exact_sd, rel=0.05)


@given(
    mean=st.floats(min_value=-100, max_value=100),
    sd=st.floats(min_value=0.001, max_value=1000),
    scalar=st.floats(min_value=-100, max_value=100),
)
def test_scale(mean, sd, scalar):
    assume(scalar != 0)
    dist = NormalDistribution(mean=mean, sd=sd)
    hist = numeric(dist)
    scaled_hist = scalar * hist
    assert scaled_hist.histogram_mean() == approx(
        scalar * hist.histogram_mean(), abs=1e-6, rel=1e-6
    )
    assert scaled_hist.histogram_sd() == approx(
        abs(scalar) * hist.histogram_sd(), abs=1e-6, rel=1e-6
    )
    assert scaled_hist.exact_mean == approx(scalar * hist.exact_mean)
    assert scaled_hist.exact_sd == approx(abs(scalar) * hist.exact_sd)


@given(
    mean=st.floats(min_value=-100, max_value=100),
    sd=st.floats(min_value=0.001, max_value=1000),
    scalar=st.floats(min_value=-100, max_value=100),
)
def test_shift_by(mean, sd, scalar):
    dist = NormalDistribution(mean=mean, sd=sd)
    hist = numeric(dist)
    shifted_hist = hist + scalar
    assert shifted_hist.histogram_mean() == approx(
        hist.histogram_mean() + scalar, abs=1e-6, rel=1e-6
    )
    assert shifted_hist.histogram_sd() == approx(hist.histogram_sd(), abs=1e-6, rel=1e-6)
    assert shifted_hist.exact_mean == approx(hist.exact_mean + scalar)
    assert shifted_hist.exact_sd == approx(hist.exact_sd)
    assert shifted_hist.pos_ev_contribution - shifted_hist.neg_ev_contribution == approx(shifted_hist.exact_mean)
    if shifted_hist.zero_bin_index < len(shifted_hist.values):
        assert shifted_hist.values[shifted_hist.zero_bin_index] > 0
    if shifted_hist.zero_bin_index > 0:
        assert shifted_hist.values[shifted_hist.zero_bin_index - 1] < 0


@given(
    norm_mean=st.floats(min_value=-10, max_value=10),
    norm_sd=st.floats(min_value=0.01, max_value=2.5),
)
def test_lognorm_reciprocal(norm_mean, norm_sd):
    dist = LognormalDistribution(norm_mean=norm_mean, norm_sd=norm_sd)
    reciprocal_dist = LognormalDistribution(norm_mean=-norm_mean, norm_sd=norm_sd)
    hist = numeric(dist, bin_sizing="log-uniform", warn=False)
    reciprocal_hist = 1 / hist
    true_reciprocal_hist = numeric(
        reciprocal_dist, bin_sizing="log-uniform", warn=False
    )

    # Taking the reciprocal does lose a good bit of accuracy because bin values
    # are set as the expected value of the bin, and the EV of 1/X is pretty
    # different. Could improve accuracy by writing
    # reciprocal_contribution_to_ev functions for every distribution type, but
    # that's probably not worth it.
    assert reciprocal_hist.histogram_mean() == approx(reciprocal_dist.lognorm_mean, rel=0.05)
    assert reciprocal_hist.histogram_sd() == approx(reciprocal_dist.lognorm_sd, rel=0.2)
    assert reciprocal_hist.neg_ev_contribution == 0
    assert reciprocal_hist.pos_ev_contribution == approx(
        true_reciprocal_hist.pos_ev_contribution, rel=0.05
    )


@given(
    norm_mean1=st.floats(min_value=-10, max_value=10),
    norm_mean2=st.floats(min_value=-10, max_value=10),
    norm_sd1=st.floats(min_value=0.01, max_value=2),
    norm_sd2=st.floats(min_value=0.01, max_value=2),
    bin_sizing1=st.sampled_from(["ev", "log-uniform"]),
)
def test_lognorm_quotient(norm_mean1, norm_mean2, norm_sd1, norm_sd2, bin_sizing1):
    dist1 = LognormalDistribution(norm_mean=norm_mean1, norm_sd=norm_sd1)
    dist2 = LognormalDistribution(norm_mean=norm_mean2, norm_sd=norm_sd2)
    hist1 = numeric(dist1, bin_sizing=bin_sizing1, warn=False)
    hist2 = numeric(dist2, bin_sizing="log-uniform", warn=False)
    quotient_hist = hist1 / hist2
    true_quotient_dist = LognormalDistribution(
        norm_mean=norm_mean1 - norm_mean2, norm_sd=np.sqrt(norm_sd1**2 + norm_sd2**2)
    )
    true_quotient_hist = numeric(
        true_quotient_dist, bin_sizing="log-uniform", warn=False
    )

    assert quotient_hist.histogram_mean() == approx(true_quotient_hist.histogram_mean(), rel=0.05)
    assert quotient_hist.histogram_sd() == approx(true_quotient_hist.histogram_sd(), rel=0.2)
    assert quotient_hist.neg_ev_contribution == approx(
        true_quotient_hist.neg_ev_contribution, rel=0.01
    )
    assert quotient_hist.pos_ev_contribution == approx(
        true_quotient_hist.pos_ev_contribution, rel=0.01
    )


@given(
    a=st.floats(min_value=1e-6, max_value=1),
    b=st.floats(min_value=1e-6, max_value=1),
)
@example(a=1, b=1)
def test_mixture(a, b):
    if a + b > 1:
        scale = a + b
        a /= scale
        b /= scale
    c = max(0, 1 - a - b)  # do max to fix floating point rounding
    dist1 = NormalDistribution(mean=0, sd=5)
    dist2 = NormalDistribution(mean=5, sd=3)
    dist3 = NormalDistribution(mean=-1, sd=1)
    mixture = MixtureDistribution([dist1, dist2, dist3], [a, b, c])
    hist = numeric(mixture, bin_sizing="uniform")
    assert hist.histogram_mean() == approx(
        a * dist1.mean + b * dist2.mean + c * dist3.mean, rel=1e-4
    )
    assert hist.values[0] < 0


def test_disjoint_mixture():
    dist = LognormalDistribution(norm_mean=0, norm_sd=1)
    hist1 = numeric(dist)
    hist2 = -numeric(dist)
    mixture = NumericDistribution.mixture([hist1, hist2], [0.97, 0.03], warn=False)
    assert mixture.histogram_mean() == approx(0.94 * dist.lognorm_mean, rel=0.001)
    assert mixture.values[0] < 0
    assert mixture.values[1] < 0
    assert mixture.values[-1] > 0
    assert mixture.contribution_to_ev(0) == approx(0.03, rel=0.1)


@given(lclip=st.integers(-4, 4), width=st.integers(1, 4))
@example(lclip=0, width=1)
def test_numeric_clip(lclip, width):
    rclip = lclip + width
    dist = NormalDistribution(mean=0, sd=1)
    full_hist = numeric(dist, num_bins=200, warn=False)
    clipped_hist = full_hist.clip(lclip, rclip)
    assert clipped_hist.histogram_mean() == approx(stats.truncnorm.mean(lclip, rclip), rel=0.1)
    hist_sum = clipped_hist + full_hist
    assert hist_sum.histogram_mean() == approx(
        stats.truncnorm.mean(lclip, rclip) + stats.norm.mean(), rel=0.1
    )


@given(
    a=st.sampled_from([0.2, 0.3, 0.5, 0.7, 0.8]),
    lclip=st.sampled_from([-1, 1, None]),
    clip_width=st.sampled_from([2, 3, None]),
    bin_sizing=st.sampled_from(["uniform", "ev", "mass"]),

    # Only clip inner or outer dist b/c clipping both makes it hard to
    # calculate what the mean should be
    clip_inner=st.booleans(),
)
@example(a=0.5, lclip=-1, clip_width=2, bin_sizing="ev", clip_inner=False)
def test_sum2_clipped(a, lclip, clip_width, bin_sizing, clip_inner):
    # Clipped NumericDist accuracy really benefits from more bins. It's not
    # very accurate with 100 bins because a clipped histogram might end up with
    # only 10 bins or so.
    num_bins = 500 if not clip_inner and bin_sizing == "uniform" else 100
    clip_outer = not clip_inner
    b = max(0, 1 - a) # do max to fix floating point rounding
    rclip = (
        lclip + clip_width
        if lclip is not None and clip_width is not None
        else np.inf
    )
    if lclip is None:
        lclip = -np.inf
    dist1 = NormalDistribution(
        mean=0,
        sd=1,
        lclip=lclip if clip_inner else None,
        rclip=rclip if clip_inner else None,
    )
    dist2 = NormalDistribution(mean=1, sd=2)
    hist = (a * numeric(dist1, num_bins, bin_sizing, warn=False) + b * numeric(dist2, num_bins, bin_sizing, warn=False))
    if clip_outer:
        hist = hist.clip(lclip, rclip)
    if clip_inner:
        # Truncating then adding is more accurate than adding then truncating,
        # which is good because truncate-then-add is the more typical use case
        true_mean = (
            a * stats.truncnorm.mean(lclip, rclip, 0, 1)
            + b * dist2.mean
        )
        tolerance = 0.01
    else:
        mixed_mean = a * dist1.mean + b * dist2.mean
        mixed_sd = np.sqrt(a**2 * dist1.sd**2 + b**2 * dist2.sd**2)
        lclip_zscore = (lclip - mixed_mean) / mixed_sd
        rclip_zscore = (rclip - mixed_mean) / mixed_sd

        true_mean = stats.truncnorm.mean(
            lclip_zscore,
            rclip_zscore,
            mixed_mean,
            mixed_sd,
        )
        tolerance = 0.2

    assert hist.histogram_mean() == approx(true_mean, rel=tolerance)


@given(
    a=st.floats(min_value=1e-6, max_value=1),
    b=st.floats(min_value=1e-6, max_value=1),
    lclip=st.sampled_from([-1, 1, None]),
    clip_width=st.sampled_from([1, 3, None]),
    bin_sizing=st.sampled_from(["uniform", "ev", "mass"]),

    # Only clip inner or outer dist b/c clipping both makes it hard to
    # calculate what the mean should be
    clip_inner=st.booleans(),
)
def test_sum3_clipped(a, b, lclip, clip_width, bin_sizing, clip_inner):
    # Clipped sum accuracy really benefits from more bins. It's not very
    # accurate with 100 bins
    num_bins = 500 if not clip_inner else 100
    clip_outer = not clip_inner
    if a + b > 1:
        scale = a + b
        a /= scale
        b /= scale
    c = max(0, 1 - a - b) # do max to fix floating point rounding
    rclip = (
        lclip + clip_width
        if lclip is not None and clip_width is not None
        else np.inf
    )
    if lclip is None:
        lclip = -np.inf
    dist1 = NormalDistribution(
        mean=0,
        sd=1,
        lclip=lclip if clip_inner else None,
        rclip=rclip if clip_inner else None,
    )
    dist2 = NormalDistribution(mean=1, sd=2)
    dist3 = NormalDistribution(mean=-1, sd=0.75)
    dist_sum = (a * dist1 + b * dist2 + c * dist3)
    if clip_outer:
        dist_sum.lclip = lclip
        dist_sum.rclip = rclip

    hist = numeric(dist_sum, num_bins=num_bins, bin_sizing=bin_sizing, warn=False)
    if clip_inner:
        true_mean = (
            a * stats.truncnorm.mean(lclip, rclip, 0, 1)
            + b * dist2.mean
            + c * dist3.mean
        )
        tolerance = 0.01
    else:
        mixed_mean = a * dist1.mean + b * dist2.mean + c * dist3.mean
        mixed_sd = np.sqrt(a**2 * dist1.sd**2 + b**2 * dist2.sd**2 + c**2 * dist3.sd**2)
        lclip_zscore = (lclip - mixed_mean) / mixed_sd
        rclip_zscore = (rclip - mixed_mean) / mixed_sd
        true_mean = stats.truncnorm.mean(
            lclip_zscore,
            rclip_zscore,
            mixed_mean,
            mixed_sd,
        )
        tolerance = 0.1
    assert hist.histogram_mean() == approx(true_mean, rel=tolerance, abs=tolerance/10)


def test_sum_with_zeros():
    dist1 = NormalDistribution(mean=3, sd=1)
    dist2 = NormalDistribution(mean=2, sd=1)
    hist1 = numeric(dist1)
    hist2 = numeric(dist2)
    hist2 = hist2.scale_by_probability(0.75)
    assert hist2.exact_mean == approx(1.5)
    assert hist2.histogram_mean() == approx(1.5, rel=1e-5)
    assert hist2.exact_sd == approx(np.sqrt(0.75 * 1**2 + 0.25 * 2**2))
    assert hist2.histogram_sd() == approx(np.sqrt(0.75 * 1**2 + 0.25 * 2**2), rel=1e-3)
    hist_sum = hist1 + hist2
    assert hist_sum.exact_mean == approx(4.5)
    assert hist_sum.histogram_mean() == approx(4.5, rel=1e-5)


def test_product_with_zeros():
    dist1 = LognormalDistribution(norm_mean=1, norm_sd=1)
    dist2 = LognormalDistribution(norm_mean=2, norm_sd=1)
    hist1 = numeric(dist1)
    hist2 = numeric(dist2)
    hist1 = hist1.scale_by_probability(2 / 3)
    hist2 = hist2.scale_by_probability(0.5)
    assert hist2.exact_mean == approx(dist2.lognorm_mean / 2)
    assert hist2.histogram_mean() == approx(dist2.lognorm_mean / 2, rel=1e-5)
    hist_prod = hist1 * hist2
    dist_prod = LognormalDistribution(norm_mean=3, norm_sd=np.sqrt(2))
    assert hist_prod.exact_mean == approx(dist_prod.lognorm_mean / 3)
    assert hist_prod.histogram_mean() == approx(dist_prod.lognorm_mean / 3, rel=1e-5)


def test_condition_on_success():
    dist1 = NormalDistribution(mean=4, sd=2)
    dist2 = LognormalDistribution(norm_mean=-1, norm_sd=1)
    hist = numeric(dist1)
    event = numeric(dist2)
    outcome = hist.condition_on_success(event)
    assert outcome.exact_mean == approx(hist.exact_mean * dist2.lognorm_mean)


def test_quantile_with_zeros():
    mean = 1
    sd = 1
    dist = NormalDistribution(mean=mean, sd=sd)
    hist = numeric(
        dist, bin_sizing="uniform", warn=False
    ).scale_by_probability(0.25)

    tolerance = 0.01

    # When we scale down by 4x, the quantile that used to be at q is now at 4q
    assert hist.quantile(0.025) == approx(stats.norm.ppf(0.1, mean, sd), rel=tolerance)
    assert hist.quantile(stats.norm.cdf(-0.01, mean, sd)/4) == approx(-0.01, rel=tolerance, abs=1e-3)

    # The values in the ~middle 75% equal 0
    assert hist.quantile(stats.norm.cdf(0.01, mean, sd)/4) == 0
    assert hist.quantile(0.4 + stats.norm.cdf(0.01, mean, sd)/4) == 0

    # The values above 0 work like the values below 0
    assert hist.quantile(0.75 + stats.norm.cdf(0.01, mean, sd)/4) == approx(0.01, rel=tolerance, abs=1e-3)
    assert hist.quantile([0.99]) == approx([stats.norm.ppf(0.96, mean, sd)], rel=tolerance)

@given(
    a=st.floats(min_value=-100, max_value=100),
    b=st.floats(min_value=-100, max_value=100),
)
@example(a=99.99999999988448, b=100.0)
@example(a=-1, b=1)
def test_uniform_basic(a, b):
    a, b = fix_uniform(a, b)
    dist = UniformDistribution(x=a, y=b)
    with warnings.catch_warnings():
        # hypothesis generates some extremely tiny input params, which
        # generates warnings about EV contributions being 0.
        warnings.simplefilter("ignore")
        hist = numeric(dist)
    assert hist.histogram_mean() == approx((a + b) / 2, 1e-6)
    assert hist.histogram_sd() == approx(np.sqrt(1 / 12 * (b - a) ** 2), rel=1e-3)


def test_uniform_sum_basic():
    # The sum of standard uniform distributions is also known as an Irwin-Hall
    # distribution:
    # https://en.wikipedia.org/wiki/Irwin%E2%80%93Hall_distribution
    dist = UniformDistribution(0, 1)
    hist1 = numeric(dist)
    hist_sum = numeric(dist)
    hist_sum += hist1
    assert hist_sum.exact_mean == approx(1)
    assert hist_sum.exact_sd == approx(np.sqrt(2 / 12))
    assert hist_sum.histogram_mean() == approx(1)
    assert hist_sum.histogram_sd() == approx(np.sqrt(2 / 12), rel=1e-3)
    hist_sum += hist1
    assert hist_sum.histogram_mean() == approx(1.5)
    assert hist_sum.histogram_sd() == approx(np.sqrt(3 / 12), rel=1e-3)
    hist_sum += hist1
    assert hist_sum.histogram_mean() == approx(2)
    assert hist_sum.histogram_sd() == approx(np.sqrt(4 / 12), rel=1e-3)


@given(
    # I originally had both dists on [-1000, 1000] but then hypothesis would
    # generate ~90% of cases with extremely tiny values that are too small for
    # floating point operations to handle, so I forced most of the values to be
    # at least a little away from 0.
    a1=st.floats(min_value=-1000, max_value=0.001),
    b1=st.floats(min_value=0.001, max_value=1000),
    a2=st.floats(min_value=0, max_value=1000),
    b2=st.floats(min_value=1, max_value=10000),
    flip2=st.booleans(),
)
def test_uniform_sum(a1, b1, a2, b2, flip2):
    if flip2:
        a2, b2 = -b2, -a2
    a1, b1 = fix_uniform(a1, b1)
    a2, b2 = fix_uniform(a2, b2)
    dist1 = UniformDistribution(x=a1, y=b1)
    dist2 = UniformDistribution(x=a2, y=b2)
    with warnings.catch_warnings():
        # hypothesis generates some extremely tiny input params, which
        # generates warnings about EV contributions being 0.
        warnings.simplefilter("ignore")
        hist1 = numeric(dist1)
        hist2 = numeric(dist2)

    hist_sum = hist1 + hist2
    assert hist_sum.histogram_mean() == approx(hist_sum.exact_mean)
    assert hist_sum.histogram_sd() == approx(hist_sum.exact_sd, rel=0.01)


@given(
    a1=st.floats(min_value=-1000, max_value=0.001),
    b1=st.floats(min_value=0.001, max_value=1000),
    a2=st.floats(min_value=0, max_value=1000),
    b2=st.floats(min_value=1, max_value=10000),
    flip2=st.booleans(),
)
def test_uniform_prod(a1, b1, a2, b2, flip2):
    if flip2:
        a2, b2 = -b2, -a2
    a1, b1 = fix_uniform(a1, b1)
    a2, b2 = fix_uniform(a2, b2)
    dist1 = UniformDistribution(x=a1, y=b1)
    dist2 = UniformDistribution(x=a2, y=b2)
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        hist1 = numeric(dist1)
        hist2 = numeric(dist2)
    hist_prod = hist1 * hist2
    assert hist_prod.histogram_mean() == approx(hist_prod.exact_mean, abs=1e-6, rel=1e-6)
    assert hist_prod.histogram_sd() == approx(hist_prod.exact_sd, rel=0.01)


@given(
    a=st.floats(min_value=-1000, max_value=0.001),
    b=st.floats(min_value=0.001, max_value=1000),
    norm_mean=st.floats(np.log(0.001), np.log(1e6)),
    norm_sd=st.floats(0.1, 2),
)
@example(a=-1000, b=999.999999970314, norm_mean=13, norm_sd=1)
def test_uniform_lognorm_prod(a, b, norm_mean, norm_sd):
    a, b = fix_uniform(a, b)
    dist1 = UniformDistribution(x=a, y=b)
    dist2 = LognormalDistribution(norm_mean=norm_mean, norm_sd=norm_sd)
    hist1 = numeric(dist1)
    hist2 = numeric(dist2, bin_sizing="ev", warn=False)
    hist_prod = hist1 * hist2
    assert hist_prod.histogram_mean() == approx(hist_prod.exact_mean, rel=1e-7, abs=1e-7)
    assert hist_prod.histogram_sd() == approx(hist_prod.exact_sd, rel=0.5)


@given(
    norm_mean=st.floats(min_value=-np.log(1e9), max_value=np.log(1e9)),
    norm_sd=st.floats(min_value=0.001, max_value=4),
    bin_num=st.integers(min_value=1, max_value=99),
)
def test_numeric_dist_contribution_to_ev(norm_mean, norm_sd, bin_num):
    fraction = bin_num / 100
    dist = LognormalDistribution(norm_mean=norm_mean, norm_sd=norm_sd)
    hist = numeric(dist, bin_sizing="ev", warn=False)
    assert hist.contribution_to_ev(dist.inv_contribution_to_ev(fraction)) == approx(fraction)


@given(
    norm_mean=st.floats(min_value=-np.log(1e9), max_value=np.log(1e9)),
    norm_sd=st.floats(min_value=0.001, max_value=4),
    bin_num=st.integers(min_value=2, max_value=98),
)
def test_numeric_dist_inv_contribution_to_ev(norm_mean, norm_sd, bin_num):
    # The nth value stored in the PMH represents a value between the nth and n+1th edges
    dist = LognormalDistribution(norm_mean=norm_mean, norm_sd=norm_sd)
    hist = numeric(dist, bin_sizing="ev", warn=False)
    fraction = bin_num / hist.num_bins
    prev_fraction = fraction - 1 / hist.num_bins
    next_fraction = fraction
    assert hist.inv_contribution_to_ev(fraction) > dist.inv_contribution_to_ev(prev_fraction)
    assert hist.inv_contribution_to_ev(fraction) < dist.inv_contribution_to_ev(next_fraction)


@given(
    mean=st.floats(min_value=-100, max_value=100),
    sd=st.floats(min_value=0.01, max_value=100),
    percent=st.integers(min_value=0, max_value=100),
)
@example(mean=0, sd=1, percent=100)
def test_quantile_uniform(mean, sd, percent):
    # Note: Quantile interpolation can sometimes give incorrect results at the
    # 0th percentile because if the first two bin edges are extremely close to
    # 0, the values can be out of order due to floating point rounding.
    assume(percent != 0 or abs(mean) / sd < 3)
    dist = NormalDistribution(mean=mean, sd=sd)
    hist = numeric(
        dist, num_bins=200, bin_sizing="uniform", warn=False
    )
    if percent == 0:
        assert hist.percentile(percent) <= hist.values[0]
    elif percent == 100:
        cum_mass = np.cumsum(hist.masses) - 0.5 * hist.masses
        nonzero_indexes = [i for (i, d) in enumerate(np.diff(cum_mass)) if d > 0]
        last_valid_index = max(nonzero_indexes)
        assert hist.percentile(percent) >= hist.values[last_valid_index]
    else:
        assert hist.percentile(percent) == approx(
            stats.norm.ppf(percent / 100, loc=mean, scale=sd), rel=0.01, abs=0.01
        )


@given(
    norm_mean=st.floats(min_value=-5, max_value=5),
    norm_sd=st.floats(min_value=0.1, max_value=2),
    percent=st.integers(min_value=1, max_value=100),
)
def test_quantile_log_uniform(norm_mean, norm_sd, percent):
    dist = LognormalDistribution(norm_mean=norm_mean, norm_sd=norm_sd)
    hist = numeric(
        dist, num_bins=200, bin_sizing="log-uniform", warn=False
    )
    if percent == 0:
        assert hist.percentile(percent) <= hist.values[0]
    elif percent == 100:
        cum_mass = np.cumsum(hist.masses) - 0.5 * hist.masses
        nonzero_indexes = [i for (i, d) in enumerate(np.diff(cum_mass)) if d > 0]
        last_valid_index = max(nonzero_indexes)
        assert hist.percentile(percent) >= hist.values[last_valid_index]
    else:
        assert hist.percentile(percent) == approx(
            stats.lognorm.ppf(percent / 100, norm_sd, scale=np.exp(norm_mean)), rel=0.01
        )


@given(
    norm_mean=st.floats(min_value=-5, max_value=5),
    norm_sd=st.floats(min_value=0.1, max_value=2),
    # Don't try smaller percentiles because the smaller bins have a lot of
    # probability mass
    percent=st.integers(min_value=20, max_value=99),
)
def test_quantile_ev(norm_mean, norm_sd, percent):
    dist = LognormalDistribution(norm_mean=norm_mean, norm_sd=norm_sd)
    hist = numeric(dist, num_bins=200, bin_sizing="ev", warn=False)
    tolerance = 0.1 if percent < 70 else 0.01
    assert hist.percentile(percent) == approx(
        stats.lognorm.ppf(percent / 100, norm_sd, scale=np.exp(norm_mean)), rel=tolerance
    )


@given(
    mean=st.floats(min_value=100, max_value=100),
    sd=st.floats(min_value=0.01, max_value=100),
    percent=st.floats(min_value=1, max_value=99),
)
@example(mean=0, sd=1, percent=1)
def test_quantile_mass(mean, sd, percent):
    dist = NormalDistribution(mean=mean, sd=sd)
    hist = numeric(dist, num_bins=200, bin_sizing="mass", warn=False)

    # It's hard to make guarantees about how close the value will be, but we
    # should know for sure that the cdf of the value is very close to the
    # percent. Naive interpolation should have a maximum absolute error of 1 /
    # num_bins.
    assert 100 * stats.norm.cdf(hist.percentile(percent), mean, sd) == approx(percent, abs=0.1)


@given(
    mean=st.floats(min_value=100, max_value=100),
    sd=st.floats(min_value=0.01, max_value=100),
)
def test_cdf_mass(mean, sd):
    dist = NormalDistribution(mean=mean, sd=sd)
    hist = numeric(dist, num_bins=200, bin_sizing="mass", warn=False)

    # should definitely be accurate to within 1 / num_bins but a smart interpolator
    # can do better
    tolerance = 0.001
    assert hist.cdf(mean) == approx(0.5, abs=tolerance)
    assert hist.cdf(mean - sd) == approx(stats.norm.cdf(-1), abs=tolerance)
    assert hist.cdf(mean + 2 * sd) == approx(stats.norm.cdf(2), abs=tolerance)


@given(
    mean=st.floats(min_value=100, max_value=100),
    sd=st.floats(min_value=0.01, max_value=100),
    percent=st.integers(min_value=1, max_value=99),
)
def test_cdf_inverts_quantile(mean, sd, percent):
    dist = NormalDistribution(mean=mean, sd=sd)
    hist = numeric(dist, num_bins=200, bin_sizing="mass", warn=False)
    assert 100 * hist.cdf(hist.percentile(percent)) == approx(percent, abs=0.1)


@given(
    mean1=st.floats(min_value=100, max_value=100),
    mean2=st.floats(min_value=100, max_value=100),
    sd1=st.floats(min_value=0.01, max_value=100),
    sd2=st.floats(min_value=0.01, max_value=100),
    percent=st.integers(min_value=1, max_value=99),
)
@example(mean1=100, mean2=100, sd1=1, sd2=99, percent=2)
def test_quantile_mass_after_sum(mean1, mean2, sd1, sd2, percent):
    dist1 = NormalDistribution(mean=mean1, sd=sd1)
    dist2 = NormalDistribution(mean=mean2, sd=sd2)
    hist1 = numeric(
        dist1, num_bins=200, bin_sizing="mass", warn=False
    )
    hist2 = numeric(
        dist2, num_bins=200, bin_sizing="mass", warn=False
    )
    hist_sum = hist1 + hist2
    assert hist_sum.percentile(percent) == approx(
        stats.norm.ppf(percent / 100, mean1 + mean2, np.sqrt(sd1**2 + sd2**2)), rel=0.01 * (mean1 + mean2)
    )
    assert 100 * stats.norm.cdf(
        hist_sum.percentile(percent), hist_sum.exact_mean, hist_sum.exact_sd
    ) == approx(percent, abs=0.25)


def test_complex_dist():
    left = NormalDistribution(mean=1, sd=1)
    right = NormalDistribution(mean=0, sd=1)
    dist = ComplexDistribution(left, right, operator.add)
    hist = numeric(dist, warn=False)
    assert hist.exact_mean == approx(1)
    assert hist.histogram_mean() == approx(1, rel=1e-6)


def test_complex_dist_with_float():
    left = NormalDistribution(mean=1, sd=1)
    right = 2
    dist = ComplexDistribution(left, right, operator.mul)
    hist = numeric(dist, warn=False)
    assert hist.exact_mean == approx(2)
    assert hist.histogram_mean() == approx(2, rel=1e-6)


def test_utils_get_percentiles_basic():
    dist = NormalDistribution(mean=0, sd=1)
    hist = numeric(dist, warn=False)
    assert utils.get_percentiles(hist, 1) == hist.percentile(1)
    assert utils.get_percentiles(hist, [5]) == hist.percentile([5])
    assert all(utils.get_percentiles(hist, np.array([10, 20])) == hist.percentile([10, 20]))


def test_plot():
    return None
    hist = numeric(
        LognormalDistribution(norm_mean=0, norm_sd=1)
    ) * numeric(NormalDistribution(mean=0, sd=5))
    # hist = numeric(LognormalDistribution(norm_mean=0, norm_sd=2))
    hist.plot(scale="linear")


def test_performance():
    return None
    # Note: I wrote some C++ code to approximate the behavior of distribution
    # multiplication. On my machine, distribution multiplication (with profile
    # = False) runs in 15s, and the equivalent C++ code (with -O3) runs in 11s.
    # The C++ code is not well-optimized, the most glaring issue being it uses
    # std::sort instead of something like argpartition (the trouble is that
    # numpy's argpartition can partition on many values simultaneously, whereas
    # C++'s std::partition can only partition on one value at a time, which is
    # far slower).
    # dist1 = NormalDistribution(mean=0, sd=1)
    dist1 = LognormalDistribution(norm_mean=0, norm_sd=1)
    dist2 = LognormalDistribution(norm_mean=1, norm_sd=0.5)

    profile = True
    if profile:
        import cProfile
        import pstats
        import io

        pr = cProfile.Profile()
        pr.enable()

    for i in range(5000):
        hist1 = numeric(dist1, num_bins=100, bin_sizing="log-uniform")
        hist2 = numeric(dist2, num_bins=100, bin_sizing="log-uniform")
        hist1 = hist1 * hist2

    if profile:
        pr.disable()
        s = io.StringIO()
        sortby = "cumulative"
        ps = pstats.Stats(pr, stream=s).sort_stats(sortby)
        ps.print_stats()
        print(s.getvalue())
